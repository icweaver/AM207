{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #8 (Due 11/06/2019, 11:59pm)\n",
    "## Variational Inference for Bayesian Neural Networks\n",
    "\n",
    "**AM 207: Advanced Scientific Computing**<br>\n",
    "**Instructor: Weiwei Pan**<br>\n",
    "**Fall 2019**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name: Ian Weaver**\n",
    "\n",
    "**Students collaborators:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "\n",
    "**Submission Format:** Use this notebook as a template to complete your homework. Please intersperse text blocks (using Markdown cells) amongst `python` code and results -- format your submission for maximum readability. Your assignments will be graded for correctness as well as clarity of exposition and presentation -- a “right” answer by itself without an explanation or is presented with a difficult to follow format will receive no credit.\n",
    "\n",
    "**Code Check:** Before submitting, you must do a \"Restart and Run All\" under \"Kernel\" in the Jupyter or colab menu. Portions of your submission that contains syntactic or run-time errors will not be graded.\n",
    "\n",
    "**Libraries and packages:** Unless a problems specifically asks you to implement from scratch, you are welcomed to use any `python` library package in the standard Anaconda distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from autograd import numpy as np\n",
    "from autograd import grad\n",
    "from autograd.misc.optimizers import adam, sgd\n",
    "from autograd import scipy as sp\n",
    "import scipy as sp_base\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "%matplotlib inline\n",
    "weqwdwqdwqwqdwqdqwwqqwadasdasdsaadadwadafasdsafasfadasfasfasfaasdasdsjhabasdvgsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_style": "center",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot configs\n",
    "fig_wide = (11, 4)\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "%matplotlib inline\n",
    "sns.set(style=\"darkgrid\", palette=\"colorblind\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "## Problem Description: Bayesian Neural Network Regression\n",
    "In Homework #7, you explored sampling from the posteriors of ***Bayesian neural networks*** using HMC. In Lab #8 you'll explore the extent to which HMC can be inefficient or ineffective for sampling from certain types of posteriors. In this homework, you will study variational approximations of BNN posteriors, especially when compared to the posteriors obtained by sampling (in Homework #7). The data is the same as the one for Homework #7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: Implement Black-Box Variational Inference with the Reparametrization Trick\n",
    "\n",
    "1. (**BBVI with the Reparametrization Trick**) Implement BBVI with the reparametrization trick for approximating an arbitrary posterior $p(w| \\text{Data})$ by an isotropic Gaussian $\\mathcal{N}(\\mu, \\Sigma)$, where $\\Sigma$ is a diagonal matrix. See Lecture #15 or the example code from [autograd's github repo](https://github.com/HIPS/autograd/blob/master/examples/black_box_svi.py). \n",
    "<br><br>\n",
    "\n",
    "2. (**Unit Test**) Check that your implementation is correct by approximating the posterior of the following Bayesian logistic regression model:\n",
    "\\begin{align}\n",
    "w &\\sim \\mathcal{N}(0, 1)\\\\\n",
    "Y^{(n)} &\\sim Ber(\\text{sigm}(wX^{(n)} + 10))\n",
    "\\end{align}\n",
    "  where $w$, $Y^{(n)}$, $X^{(n)}$ are a real scalar valued random variables, and where the data consists of a single observation $(Y=1, X=-20)$.\n",
    "\n",
    "  The true posterior $p(w | Y=1, X=-20)$ should look like the following (i.e. the true posterior is left-skewed):\n",
    "<img src=\"./logistic_posterior.png\" style='height:200px;'>\n",
    "  Your mean-field variational approximation should be a Gaussian with mean -0.321 and standard deviation 0.876 (all approximate).\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 BBVI with the Reparametrization Trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_box_variational_inference(logprob, D, num_samples):\n",
    "    \n",
    "    \"\"\"\n",
    "    Implements http://arxiv.org/abs/1401.0118, and uses the\n",
    "    local reparameterization trick from http://arxiv.org/abs/1506.02557\n",
    "    code taken from:\n",
    "    https://github.com/HIPS/autograd/blob/master/examples/black_box_svi.py\n",
    "    \"\"\"\n",
    "\n",
    "    def unpack_params(params):\n",
    "        # Variational dist is a diagonal Gaussian.\n",
    "        mean, log_std = params[:D], params[D:]\n",
    "        return mean, log_std\n",
    "\n",
    "    def gaussian_entropy(log_std):\n",
    "        return 0.5 * D * (1.0 + np.log(2*np.pi)) + np.sum(log_std)\n",
    "\n",
    "    rs = np.random.RandomState(0)\n",
    "    def variational_objective(params, t):\n",
    "        \"\"\"Provides a stochastic estimate of the variational lower bound.\"\"\"\n",
    "        mean, log_std = unpack_params(params)\n",
    "        samples = rs.randn(num_samples, D) * np.exp(log_std) + mean\n",
    "        lower_bound = gaussian_entropy(log_std) + np.mean(logprob(samples, t))\n",
    "        return -lower_bound\n",
    "\n",
    "    gradient = grad(variational_objective)\n",
    "\n",
    "    return variational_objective, gradient, unpack_params\n",
    "\n",
    "\n",
    "def variational_inference(Sigma_W, y, x, S, max_iteration, step_size, verbose):\n",
    "    '''implements wrapper for variational inference via bbb for bayesian regression'''\n",
    "    D = Sigma_W.shape[0]\n",
    "    Sigma_W_inv = np.linalg.inv(Sigma_W)\n",
    "    Sigma_W_det = np.linalg.det(Sigma_W)\n",
    "    variational_dim = D\n",
    "    \n",
    "    sigmoid = lambda x: 1. / (1. + np.exp(-x))\n",
    "    \n",
    "    #define the log prior on the model parameters\n",
    "    # multivariate normal\n",
    "    def log_prior(W):\n",
    "        constant_W = -0.5 * (D * np.log(2 * np.pi) + np.log(Sigma_W_det))\n",
    "        exponential_W = -0.5 * np.diag(np.dot(np.dot(W, Sigma_W_inv), W.T))\n",
    "        log_p_W = constant_W + exponential_W\n",
    "        return log_p_W\n",
    "\n",
    "    #define the log likelihood\n",
    "    # bernouilli\n",
    "    def log_lklhd(W):\n",
    "        bern_arg = sigmoid(W*1 + 10.)\n",
    "        return np.log(bern_arg)\n",
    "\n",
    "    #define the log joint density\n",
    "    log_density = lambda w, t: log_lklhd(w) + log_prior(w)\n",
    "\n",
    "    #build variational objective.\n",
    "    objective, gradient, unpack_params = \\\n",
    "    black_box_variational_inference(log_density, D, num_samples=S)\n",
    "\n",
    "    def callback(params, t, g):\n",
    "        if verbose:\n",
    "            if  t % 100 == 0:\n",
    "                print(\n",
    "                    \"Iteration {} lower bound {}; gradient mag: {}\".format(\n",
    "                    t, \n",
    "                    -objective(params, t), \n",
    "                    np.linalg.norm(gradient(params, t))\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    print(\"Optimizing variational parameters...\")\n",
    "    #initialize variational parameters\n",
    "    init_mean = np.ones(D)\n",
    "    init_log_std = -100 * np.ones(D)\n",
    "    init_var_params = np.concatenate([init_mean, init_log_std])\n",
    "    \n",
    "    #perform gradient descent using adam (a type of gradient-based optimizer)\n",
    "    variational_params = adam(gradient, init_var_params, step_size=step_size, num_iters=max_iteration, callback=callback)\n",
    "    \n",
    "    return variational_params "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Unit Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing variational parameters...\n",
      "Iteration 0 lower bound -100.00001670156132; gradient mag: 1.414201752733763\n",
      "Iteration 100 lower bound -89.50004981737577; gradient mag: 1.0000043196938413\n",
      "Iteration 200 lower bound -79.50004559789356; gradient mag: 1.000000000025754\n",
      "Iteration 300 lower bound -69.50004569786732; gradient mag: 1.0000000000000022\n",
      "Iteration 400 lower bound -59.50004579786711; gradient mag: 1.0\n",
      "Iteration 500 lower bound -49.50004589786733; gradient mag: 1.0\n",
      "Iteration 600 lower bound -39.50004599786755; gradient mag: 1.0\n",
      "Iteration 700 lower bound -29.5000460978677; gradient mag: 1.0\n",
      "Iteration 800 lower bound -19.500046197867565; gradient mag: 1.0\n",
      "Iteration 900 lower bound -9.500046299394446; gradient mag: 0.9999999978847491\n",
      "Iteration 1000 lower bound -0.022685003127555392; gradient mag: 0.27358365434731496\n",
      "Iteration 1100 lower bound 0.009311992239024125; gradient mag: 0.027719792589524245\n",
      "Iteration 1200 lower bound 0.03386541529436227; gradient mag: 0.054183652310202765\n",
      "Iteration 1300 lower bound 0.055942941744696384; gradient mag: 0.11642992937213072\n",
      "Iteration 1400 lower bound 0.03549922768313318; gradient mag: 0.14423341853487726\n",
      "Iteration 1500 lower bound -0.002515054046658971; gradient mag: 0.1209818370928018\n",
      "Iteration 1600 lower bound -0.023158092763371885; gradient mag: 0.010359235124336666\n",
      "Iteration 1700 lower bound 0.05161049531582229; gradient mag: 0.08705252397715357\n",
      "Iteration 1800 lower bound -0.08375666202327481; gradient mag: 0.053245580830327065\n",
      "Iteration 1900 lower bound -0.010015202171748339; gradient mag: 0.09175984012837643\n"
     ]
    }
   ],
   "source": [
    "## load data\n",
    "x = np.array([-20.])\n",
    "y = np.array([1.])\n",
    "D = 1\n",
    "\n",
    "# VI params\n",
    "Sigma_W = np.array([[1]])\n",
    "S = 400\n",
    "max_iteration = 2_000\n",
    "step_size = 1e-1\n",
    "verbose=True\n",
    "\n",
    "vi_params = variational_inference(Sigma_W, x, y, S, max_iteration, step_size, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0161316] [[1.00615344]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 251,
       "width": 377
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vi_params[:D]\n",
    "var_means = vi_params[:D]\n",
    "var_variance = np.diag(np.exp(vi_params[D:])**2)\n",
    "print(var_means, np.sqrt(var_variance))\n",
    "x = np.random.normal(loc=var_means, scale=np.sqrt(var_variance), size=1_000)\n",
    "plt.hist(x, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: Approximate the Posterior of a Bayesian Neural Network\n",
    "\n",
    "1. (**Variational Inference for BNNs**) We will implement the following Bayesian model for the data:\n",
    "\\begin{align}\n",
    "\\mathbf{W} &\\sim \\mathcal{N}(0, 5^2 \\mathbf{I}_{D\\times D})\\\\\n",
    "\\mu^{(n)} &= g_{\\mathbf{W}}(\\mathbf{X}^{(n)})\\\\\n",
    "Y^{(n)} &\\sim \\mathcal{N}(\\mu^{(n)}, 0.5^2)\n",
    "\\end{align}\n",
    "  where $g_{\\mathbf{W}}$ is a neural network with parameters $\\mathbf{W}$ represented as a vector in $\\mathbb{R}^{D}$ with $D$ being the total number of parameters (including biases). Just as in HW #7, use a network with a single hidden layer, 5 hidden nodes and rbf activation function.\n",
    "\n",
    "  Implement the log of the joint distribution in `autograd`'s version of `numpy`, i.e. implement $\\log \\left[p(\\mathbf{W})\\prod_{n=1}^N p(Y^{(n)} |\\mathbf{X}^{(n)} , \\mathbf{W}) \\right]$.\n",
    "  \n",
    "  ***Hint:*** you'll need to write out the log of the various Gaussian pdf's and implement their formulae using `autograd`'s numpy functions.<br><br>\n",
    "\n",
    "4. (**Approximate the Posterior**) Use BBVI with the reparametrization trick to approximate the posterior of the Bayesian neural network with a mean-field Gaussian variational family (i.e. an isotropic Gaussian). Please set learning rate and maximum iteration choices as you see fit!<br><br>\n",
    "  \n",
    "4. (**Visualize the Posterior Predictive**) Visualize 100 samples $\\mathbf{W}^s$ from your approximate posterior of $\\mathbf{W}$ by ploting the neural network outputs with weight $\\mathbf{W}^s$ plus a random noise $\\epsilon \\sim \\mathcal{N}(0, 0.5^2)$ at 100 equally spaced x-values between -8 and 8:\n",
    "``` python \n",
    "x_test = np.linspace(-8, 8, 100)\n",
    "y_test = nn.forward(sample, x_test.reshape((1, -1)))\n",
    "```\n",
    "  where `sample` is a sample from the approximate posterior of $\\mathbf{W}$.<br><br>\n",
    "\n",
    "5. (**Computing the Fit**) Compute the posterior predictive log likelihood of the observed data under your model. \n",
    "<br><br>\n",
    "  \n",
    "6. (**Model Evaluation**) Compare the posterior predictive visualization and the posterior predictive log likelihood obtained from BBVI with the reparametrization trick to the ones you obtained in HW #7. Can you say whether or not your posterior approximation is good? How does approximating the posterior effect our estimation of epistemic and aleatoric uncertainty?<br><br>\n",
    "\n",
    "7. (**Extra Credit**) Get your HMC sampler to converge for this BNN model and this dataset.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "239.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
